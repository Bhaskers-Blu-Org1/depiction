{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from depiction.models.base.base_model import BaseModel\n",
    "from depiction.models.examples.celltype.celltype import CellTyper\n",
    "from depiction.interpreters.u_wash.u_washer import UWasher\n",
    "from depiction.interpreters.aix360.rule_based_model import RuleAIX360\n",
    "from depiction.models.base import BinarizedClassifier\n",
    "from depiction.core import Task, DataType\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "datapath = 'data/single-cell/data.csv'  # '../data/single-cell/data.csv'\n",
    "data_df = pd.read_csv(datapath)\n",
    "sns.countplot(data_df.category)\n",
    "\n",
    "#scale the data from 0 to 1\n",
    "min_max_scaler = MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "data = min_max_scaler.fit_transform(data_df.drop('category', axis=1).values)\n",
    "data_df = pd.DataFrame(\n",
    "    np.append(data, data_df['category'].values[:, None], axis=1), index=data_df.index, columns=data_df.columns\n",
    ")\n",
    "\n",
    "#  split as in traing of the model\n",
    "train_df, test_df = train_test_split(data_df, test_size=0.33, random_state=42, stratify=data_df.category)\n",
    "test_df, valid_df = train_test_split(test_df, test_size=0.67, stratify=test_df.category)\n",
    "\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CellTyper.celltype_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading a pretrained model\n",
    "is actually done under the hood by a child implementation of `depiction.models.Model`  \n",
    "Change `filename` (there's also `cache_dir`) to load a different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import trained classifier\n",
    "classifier = CellTyper(filename='celltype_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Layer weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = classifier.model.layers[0].get_weights()[0]\n",
    "sns.heatmap(pd.DataFrame(\n",
    "    weights,\n",
    "    index=data_df.columns[:-1],\n",
    "#     columns=CellTyper.celltype_names.values()\n",
    ").T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Compare qualitatively to __B__ and **C** (thought the image is not depicting this exact dataset)\n",
    "![manual_gated](https://science.sciencemag.org/content/sci/332/6030/687/F2.large.jpg?width=800&height=600&carousel=1)\n",
    "from https://science.sciencemag.org/content/332/6030/687/tab-figures-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Interpretability methods\n",
    "helper functions and a widget to sample from a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_from_class(label):\n",
    "    id_sample_to_explain = test_df.reset_index().query('category==@label').sample(n=1).index[0]\n",
    "    print('Interpreting sample with index {} in test_df'.format(id_sample_to_explain))\n",
    "    return id_sample_to_explain\n",
    "\n",
    "\n",
    "def interpret_with_lime(id_sample_to_explain):\n",
    "# Create a LIME tabular interpreter\n",
    "    explanation_configs = {\n",
    "        'top_labels': 1\n",
    "    }\n",
    "    interpreter_params = {\n",
    "        'training_data': train_df.values[:, :-1],\n",
    "        'training_labels': train_df.values[:, -1],\n",
    "        'feature_names': train_df.columns[:-1],\n",
    "        'verbose': True,\n",
    "        'class_names': classifier.celltype_names.values(),\n",
    "        'discretize_continuous': False,\n",
    "        'sample_around_instance': True\n",
    "    }\n",
    "\n",
    "    explainer = UWasher(\"lime\", classifier, **interpreter_params)\n",
    "\n",
    "    # explain the chosen instance wrt the chosen labels\n",
    "    explainer.interpret(test_df.values[id_sample_to_explain, :-1], explanation_configs=explanation_configs)\n",
    "\n",
    "\n",
    "def interpret_with_anchor(id_sample_to_explain):\n",
    "    explanation_configs = {}\n",
    "    interpreter_params = {\n",
    "        'feature_names': train_df.columns[:-1],\n",
    "        'class_names': classifier.celltype_names.values(),\n",
    "        'categorical_names': {}\n",
    "    }\n",
    "\n",
    "    explainer = UWasher('anchors', classifier, **interpreter_params)\n",
    "    X_train = train_df.values[:, :-1]\n",
    "    y_train = train_df.values[:, -1].astype(np.int)\n",
    "    X_valid = valid_df.values[:, :-1]\n",
    "    y_valid = valid_df.values[:, -1].astype(np.int)\n",
    "    explainer.explainer.fit(\n",
    "        X_train, y_train, X_valid, y_valid\n",
    "    )\n",
    "\n",
    "    # explain the chosen instance wrt the chosen labels\n",
    "    def new_predict(sample, **kwargs):\n",
    "        return np.argmax(classifier.predict(sample,**kwargs), axis=1)\n",
    "    explainer.interpret(test_df.values[id_sample_to_explain, :-1], explanation_configs=explanation_configs,callback=new_predict)\n",
    "\n",
    "\n",
    "def visualize_logits(id_sample_to_explain):\n",
    "    sample = test_df.iloc[id_sample_to_explain,:-1]\n",
    "    logits = pd.DataFrame(classifier.predict([[sample]]), columns=CellTyper.celltype_names.values()).T\n",
    "    sns.heatmap(logits)\n",
    "\n",
    "\n",
    "def visualize(id_sample_to_explain, layer):\n",
    "    sample = test_df.iloc[id_sample_to_explain,:-1]\n",
    "    if layer is None:\n",
    "        visualize_logits(id_sample_to_explain)\n",
    "        return\n",
    "    elif layer==0:\n",
    "        # output of last \"layer\" is the sample\n",
    "        layer_output = sample.values.transpose()\n",
    "    else:\n",
    "        # for vizualization of output of a layer we access the model\n",
    "        activation_model = keras.models.Model(\n",
    "            inputs=classifier.model.input,\n",
    "            outputs=classifier.model.layers[layer-1].output\n",
    "        )\n",
    "        layer_output = activation_model.predict([[sample]])[0]\n",
    "    \n",
    "    weights = classifier.model.layers[layer].get_weights()[0]\n",
    "    weighted_output = (weights.transpose() * layer_output)\n",
    "    sns.heatmap(weighted_output)\n",
    "\n",
    "\n",
    "def visualize_random_from_class(label, layer):\n",
    "    visualize(random_from_class(label), layer)\n",
    "\n",
    "    \n",
    "def interpret_random_from_class(label, interpreter):\n",
    "    id_sample_to_explain = random_from_class(label)\n",
    "    if interpreter == 'lime':\n",
    "        interpret_with_lime(id_sample_to_explain)\n",
    "    elif interpreter == 'anchor':\n",
    "        interpret_with_anchor(id_sample_to_explain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_manual(\n",
    "    visualize_random_from_class,\n",
    "    label=[(v, k) for k, v in classifier.celltype_names.items()],\n",
    "    layer=dict(\n",
    "        **{layer.name: i for i, layer in enumerate(classifier.model.layers)}, logits=None\n",
    "    )\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_logits(4368)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_manual(interpret_random_from_class, label=[(v, k) for k, v in classifier.celltype_names.items()],\n",
    "         interpreter=['lime', 'anchor']\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_with_anchor(4368)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global interpretation with rule-based models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL2ID = {CellTyper.celltype_names[i]: i for i in range(1, len(CellTyper.celltype_names)+1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_TO_EXPLAIN = 'Mature CD4+ T'\n",
    "LABEL_ID = LABEL2ID[LABEL_TO_EXPLAIN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data preparation and auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = train_df.columns[:-1]\n",
    "\n",
    "X_train = train_df[markers]\n",
    "X_test = test_df[markers]\n",
    "\n",
    "y_train = np.array(train_df['category'] == np.float(LABEL_ID), np.int)\n",
    "y_test = np.array(test_df['category'] == np.float(LABEL_ID), np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Post-Hoc explanation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize the task to use this method\n",
    "model = BinarizedClassifier(classifier, data_type=DataType.TABULAR, label_index=LABEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BRCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = RuleAIX360('brcg', X=X_train, model=model)\n",
    "interpreter.interpret()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GLRM - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = RuleAIX360('glrm_linear', X=X_train, model=model)\n",
    "interpreter.interpret()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GLRM - Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = RuleAIX360('glrm_logistic', X=X_train, model=model)\n",
    "interpreter.interpret()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ante-Hoc explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BRCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = RuleAIX360('brcg', X=X_train, y=y_train)\n",
    "interpreter.interpret()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GLRM - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = RuleAIX360('glrm_linear', X=X_train, y=y_train)\n",
    "interpreter.interpret()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GLRM - Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = RuleAIX360('glrm_logistic', X=X_train, y=y_train)\n",
    "interpreter.interpret()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}