{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from depiction.models.celltype import CellTyper\n",
    "from depiction.interpreters.uw_model import UWModel\n",
    "from depiction.core import Task, DataType\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "datapath = '../data/single-cell/data.csv'\n",
    "data_df = pd.read_csv(datapath)\n",
    "sns.countplot(data_df.category)\n",
    "\n",
    "#scale the data from 0 to 1\n",
    "min_max_scaler = MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "data = min_max_scaler.fit_transform(data_df.drop('category', axis=1).values)\n",
    "data_df = pd.DataFrame(\n",
    "    np.append(data, data_df[\"category\"].values[:, None], axis=1), index=data_df.index, columns=data_df.columns\n",
    ")\n",
    "\n",
    "#  split as in traing of the model\n",
    "train_df, test_df = train_test_split(data_df, test_size=0.33, random_state=42, stratify=data_df.category)\n",
    "test_df, valid_df = train_test_split(test_df, test_size=0.67, stratify=test_df.category)\n",
    "\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CellTyper.celltype_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a pretrained model\n",
    "is actually done under the hood by a child implementation of `depiction.models.Model`  \n",
    "Change `filename` (there's also `cache_dir`) to load a different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import trained classifier\n",
    "classifier = CellTyper(filename='celltype_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = classifier.model.layers[0].get_weights()[0]\n",
    "sns.heatmap(pd.DataFrame(\n",
    "    weights,\n",
    "    index=data_df.columns[:-1],\n",
    "#     columns=CellTyper.celltype_names.values()\n",
    ").T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare qualitatively to __B__ and **C** (thought the image is not depicting this exact dataset)\n",
    "![manual_gated](https://science.sciencemag.org/content/sci/332/6030/687/F2.large.jpg?width=800&height=600&carousel=1)\n",
    "from https://science.sciencemag.org/content/332/6030/687/tab-figures-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretability methods\n",
    "helper functions and a widget to sample from a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_from_class(label):\n",
    "    id_sample_to_explain = test_df.reset_index().query('category==@label').sample(n=1).index[0]\n",
    "    print(f\"Interpreting sample with index {id_sample_to_explain} in test_df\")\n",
    "    return id_sample_to_explain\n",
    "\n",
    "\n",
    "def interpret_with_lime(id_sample_to_explain):\n",
    "# Create a LIME tabular interpreter\n",
    "    explanation_configs = {\n",
    "        \"top_labels\": 1\n",
    "    }\n",
    "    interpreter_params = {\n",
    "        \"training_data\": train_df.values[:, :-1],\n",
    "        \"training_labels\": train_df.values[:, -1],\n",
    "        \"feature_names\": train_df.columns[:-1],\n",
    "        \"verbose\": True,\n",
    "        \"class_names\": classifier.celltype_names.values(),\n",
    "        \"discretize_continuous\": False,\n",
    "        \"sample_around_instance\": True\n",
    "    }\n",
    "\n",
    "    explainer = UWModel(\"lime\", Task.CLASSIFICATION, DataType.TABULAR, explanation_configs, **interpreter_params)\n",
    "\n",
    "    # explain the chosen instance wrt the chosen labels\n",
    "    explainer.interpret(classifier.predict, test_df.values[id_sample_to_explain, :-1])\n",
    "\n",
    "\n",
    "def interpret_with_anchor(id_sample_to_explain):\n",
    "    explanation_configs = {}\n",
    "    interpreter_params = {\n",
    "        \"feature_names\": train_df.columns[:-1],\n",
    "        \"class_names\": classifier.celltype_names.values(),\n",
    "        \"categorical_names\": {}\n",
    "    }\n",
    "\n",
    "    explainer = UWModel(\"anchor\", Task.CLASSIFICATION, DataType.TABULAR, explanation_configs, **interpreter_params)\n",
    "    X_train = train_df.values[:, :-1]\n",
    "    y_train = train_df.values[:, -1].astype(np.int)\n",
    "    X_valid = valid_df.values[:, :-1]\n",
    "    y_valid = valid_df.values[:, -1].astype(np.int)\n",
    "    explainer.explainer.fit(\n",
    "        X_train, y_train, X_valid, y_valid\n",
    "    )\n",
    "\n",
    "    # explain the chosen instance wrt the chosen labels\n",
    "    def new_predict(sample, **kwargs):\n",
    "        return np.argmax(classifier.predict(sample,**kwargs), axis=1)\n",
    "    explainer.interpret(new_predict, test_df.values[id_sample_to_explain, :-1])\n",
    "\n",
    "\n",
    "def visualize_logits(id_sample_to_explain):\n",
    "    sample = test_df.iloc[id_sample_to_explain,:-1]\n",
    "    logits = pd.DataFrame(classifier.predict([[sample]]), columns=CellTyper.celltype_names.values()).T\n",
    "    sns.heatmap(logits)\n",
    "\n",
    "\n",
    "def visualize(id_sample_to_explain, layer):\n",
    "    sample = test_df.iloc[id_sample_to_explain,:-1]\n",
    "    if layer is None:\n",
    "        visualize_logits(id_sample_to_explain)\n",
    "        return\n",
    "    elif layer==0:\n",
    "        # output of last \"layer\" is the sample\n",
    "        layer_output = sample.values.transpose()\n",
    "    else:\n",
    "        # for vizualization of output of a layer we access the model\n",
    "        activation_model = keras.models.Model(\n",
    "            inputs=classifier.model.input,\n",
    "            outputs=classifier.model.layers[layer-1].output\n",
    "        )\n",
    "        layer_output = activation_model.predict([[sample]])[0]\n",
    "    \n",
    "    weights = classifier.model.layers[layer].get_weights()[0]\n",
    "    weighted_output = (weights.transpose() * layer_output)\n",
    "    sns.heatmap(weighted_output)\n",
    "\n",
    "\n",
    "def visualize_random_from_class(label, layer):\n",
    "    visualize(random_from_class(label), layer)\n",
    "\n",
    "    \n",
    "def interpret_random_from_class(label, interpreter):\n",
    "    id_sample_to_explain = random_from_class(label)\n",
    "    if interpreter==\"lime\":\n",
    "        interpret_with_lime(id_sample_to_explain)\n",
    "    elif interpreter==\"anchor\":\n",
    "        interpret_with_anchor(id_sample_to_explain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_manual(\n",
    "    visualize_random_from_class,\n",
    "    label=[(v, k) for k, v in classifier.celltype_names.items()],\n",
    "    layer=dict(\n",
    "        **{layer.name: i for i, layer in enumerate(classifier.model.layers)}, logits=None\n",
    "    )\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_logits(4368)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_manual(interpret_random_from_class, label=[(v, k) for k, v in classifier.celltype_names.items()],\n",
    "         interpreter=[\"lime\", \"anchor\"]\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_with_anchor(4368)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
